Hi,

After quick preview of the code, one question certainly comes to mind - what is the point of writing such network from the absolute bottom?
And the question is right, comparing it for instance to predefined algorithms in pytnon, this one is slow, not optymalized in any way,
gery very far from perfect, however the point of entire project wasn't about making super quick solution to this particular problem,
but rather to experience how neural networks works from inside.
MNIST dataset served only as helpful tool in order to accomplish this goal.

Entirety was written with significant help coming from Michael Nielsen's book
(which I therefore strongly recommend  -> http://neuralnetworksanddeeplearning.com/index.html)
followed by his github repository  -> https://github.com/mnielsen/neural-networks-and-deep-learning/tree/d15df08a69ed33ae16a2fff874f83b57a956172c.

Since you're here, I hope you will find some use of this repository as well.

Thanks!
